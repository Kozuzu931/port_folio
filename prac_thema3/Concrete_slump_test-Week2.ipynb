{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>34.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>163.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>162.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>162.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>42.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>154.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>26.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1     x2     x3     x4     x5    x6     x7     x8    x9   x10      y\n",
       "0   1  273.0   82.0  105.0  210.0   9.0  904.0  680.0  23.0  62.0  34.99\n",
       "1   2  163.0  149.0  191.0  180.0  12.0  843.0  746.0   0.0  20.0  41.14\n",
       "2   3  162.0  148.0  191.0  179.0  16.0  840.0  743.0   1.0  20.0  41.81\n",
       "3   4  162.0  148.0  190.0  179.0  19.0  838.0  741.0   3.0  21.5  42.08\n",
       "4   5  154.0  112.0  144.0  220.0  10.0  923.0  658.0  20.0  64.0  26.82"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalization.\n",
    "import pandas as pd\n",
    "\n",
    "d = pd.read_csv('6_Concrete_Slump_test/slump_test.data.txt', sep=',',header=None,skiprows=1,names=('x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','y'))\n",
    "d.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 121 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Scatter plot.\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas.tools.plotting import scatter_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.911\n",
      "Model:                            OLS   Adj. R-squared:                  0.901\n",
      "Method:                 Least Squares   F-statistic:                     93.80\n",
      "Date:                Thu, 10 Jan 2019   Prob (F-statistic):           8.86e-44\n",
      "Time:                        11:24:32   Log-Likelihood:                -233.33\n",
      "No. Observations:                 103   AIC:                             488.7\n",
      "Df Residuals:                      92   BIC:                             517.6\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         86.1142     88.371      0.974      0.332     -89.399     261.627\n",
      "x1            -0.0123      0.013     -0.950      0.344      -0.038       0.013\n",
      "x2             0.0778      0.029      2.670      0.009       0.020       0.136\n",
      "x3            -0.0066      0.040     -0.162      0.872      -0.087       0.074\n",
      "x4             0.0663      0.030      2.202      0.030       0.007       0.126\n",
      "x5            -0.1811      0.089     -2.034      0.045      -0.358      -0.004\n",
      "x6             0.0668      0.134      0.497      0.620      -0.200       0.334\n",
      "x7            -0.0332      0.035     -0.961      0.339      -0.102       0.035\n",
      "x8            -0.0165      0.035     -0.467      0.642      -0.087       0.054\n",
      "x9            -0.2287      0.076     -2.995      0.004      -0.380      -0.077\n",
      "x10            0.0839      0.044      1.901      0.060      -0.004       0.172\n",
      "==============================================================================\n",
      "Omnibus:                        1.471   Durbin-Watson:                   1.857\n",
      "Prob(Omnibus):                  0.479   Jarque-Bera (JB):                1.061\n",
      "Skew:                           0.236   Prob(JB):                        0.588\n",
      "Kurtosis:                       3.154   Cond. No.                     4.39e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.39e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "\n",
    "#MR with full IVs.\n",
    "y=d[['y']]\n",
    "X = d.loc[:, d.columns != 'y']\n",
    "\n",
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(y, sm.add_constant(X))\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.911\n",
      "Model:                            OLS   Adj. R-squared:                  0.901\n",
      "Method:                 Least Squares   F-statistic:                     93.80\n",
      "Date:                Thu, 10 Jan 2019   Prob (F-statistic):           8.86e-44\n",
      "Time:                        11:24:53   Log-Likelihood:                -21.751\n",
      "No. Observations:                 103   AIC:                             65.50\n",
      "Df Residuals:                      92   BIC:                             94.48\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -2.776e-16      0.031  -8.91e-15      1.000      -0.062       0.062\n",
      "x1            -0.0470      0.049     -0.950      0.344      -0.145       0.051\n",
      "x2             0.7832      0.293      2.670      0.009       0.201       1.366\n",
      "x3            -0.0506      0.312     -0.162      0.872      -0.670       0.569\n",
      "x4             0.7228      0.328      2.202      0.030       0.071       1.375\n",
      "x5            -0.4670      0.230     -2.034      0.045      -0.923      -0.011\n",
      "x6             0.0239      0.048      0.497      0.620      -0.072       0.120\n",
      "x7            -0.3745      0.390     -0.961      0.339      -1.148       0.399\n",
      "x8            -0.1337      0.286     -0.467      0.642      -0.702       0.435\n",
      "x9            -0.2553      0.085     -2.995      0.004      -0.425      -0.086\n",
      "x10            0.1881      0.099      1.901      0.060      -0.008       0.385\n",
      "==============================================================================\n",
      "Omnibus:                        1.471   Durbin-Watson:                   1.857\n",
      "Prob(Omnibus):                  0.479   Jarque-Bera (JB):                1.061\n",
      "Skew:                           0.236   Prob(JB):                        0.588\n",
      "Kurtosis:                       3.154   Cond. No.                         42.2\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "\n",
    "#Normalization.\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y_scaled = preprocessing.scale(y)\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "mod = sm.OLS(y_scaled, sm.add_constant(X_scaled))\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_aic(model, exog, endog, **kwargs):\n",
    "    \"\"\"\n",
    "    This select the best exogenous variables with AIC\n",
    "    Both exog and endog values can be either str or list.\n",
    "    (Endog list is for the Binomial family.)\n",
    "\n",
    "    Note: This adopt only \"forward\" selection\n",
    "\n",
    "    Args:\n",
    "        model: model from statsmodels.formula.api\n",
    "        exog (str or list): exogenous variables\n",
    "        endog (str or list): endogenous variables\n",
    "        kwargs: extra keyword argments for model (e.g., data, family)\n",
    "\n",
    "    Returns:\n",
    "        model: a model that seems to have the smallest AIC\n",
    "    \"\"\"\n",
    "\n",
    "    # exog, endogは強制的にリスト形式に変換しておく\n",
    "    exog = np.r_[[exog]].flatten()\n",
    "    endog = np.r_[[endog]].flatten()\n",
    "    remaining = set(exog)\n",
    "    selected = []  # 採用が確定された要因\n",
    "\n",
    "    # 定数項のみのAICを計算\n",
    "    formula_head = ' + '.join(endog) + ' ~ '\n",
    "    formula = formula_head + '1'\n",
    "    aic = model(formula=formula, **kwargs).fit().aic\n",
    "    print('AIC: {}, formula: {}'.format(round(aic, 3), formula))\n",
    "\n",
    "    current_score, best_new_score = np.ones(2) * aic\n",
    "\n",
    "    # 全要因を採択するか，どの要因を追加してもAICが上がらなければ終了\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in list(remaining):\n",
    "\n",
    "            # 残っている要因を1つずつ追加したときのAICを計算\n",
    "            formula_tail = ' + '.join(selected + [candidate])\n",
    "            formula = formula_head + formula_tail\n",
    "            aic = model(formula=formula, **kwargs).fit().aic\n",
    "            print('AIC: {}, formula: {}'.format(round(aic, 3), formula))\n",
    "\n",
    "            scores_with_candidates.append((aic, candidate))\n",
    "\n",
    "        # 最もAICが小さかった要因をbest_candidateとする\n",
    "        scores_with_candidates.sort()\n",
    "        scores_with_candidates.reverse()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "\n",
    "        # 候補要因追加でAICが下がったならば，それを確定要因として追加する\n",
    "        if best_new_score < current_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "\n",
    "    formula = formula_head + ' + '.join(selected)\n",
    "    print('The best formula: {}'.format(formula))\n",
    "    return model(formula, **kwargs).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC: 294.301, formula: y ~ 1\n",
      "AIC: 284.068, formula: y ~ x5\n",
      "AIC: 292.664, formula: y ~ x10\n",
      "AIC: 285.583, formula: y ~ x7\n",
      "AIC: 296.294, formula: y ~ x9\n",
      "AIC: 283.582, formula: y ~ x3\n",
      "AIC: 296.198, formula: y ~ x1\n",
      "AIC: 291.092, formula: y ~ x6\n",
      "AIC: 294.307, formula: y ~ x4\n",
      "AIC: 295.643, formula: y ~ x2\n",
      "AIC: 296.157, formula: y ~ x8\n",
      "AIC: 275.378, formula: y ~ x3 + x5\n",
      "AIC: 285.406, formula: y ~ x3 + x10\n",
      "AIC: 279.381, formula: y ~ x3 + x7\n",
      "AIC: 285.493, formula: y ~ x3 + x9\n",
      "AIC: 282.795, formula: y ~ x3 + x1\n",
      "AIC: 282.33, formula: y ~ x3 + x6\n",
      "AIC: 285.19, formula: y ~ x3 + x4\n",
      "AIC: 285.464, formula: y ~ x3 + x2\n",
      "AIC: 284.864, formula: y ~ x3 + x8\n",
      "AIC: 277.09, formula: y ~ x3 + x5 + x10\n",
      "AIC: 270.839, formula: y ~ x3 + x5 + x7\n",
      "AIC: 277.287, formula: y ~ x3 + x5 + x9\n",
      "AIC: 276.166, formula: y ~ x3 + x5 + x1\n",
      "AIC: 274.725, formula: y ~ x3 + x5 + x6\n",
      "AIC: 275.589, formula: y ~ x3 + x5 + x4\n",
      "AIC: 275.613, formula: y ~ x3 + x5 + x2\n",
      "AIC: 277.363, formula: y ~ x3 + x5 + x8\n",
      "AIC: 272.622, formula: y ~ x3 + x5 + x7 + x10\n",
      "AIC: 272.806, formula: y ~ x3 + x5 + x7 + x9\n",
      "AIC: 272.04, formula: y ~ x3 + x5 + x7 + x1\n",
      "AIC: 272.567, formula: y ~ x3 + x5 + x7 + x6\n",
      "AIC: 271.303, formula: y ~ x3 + x5 + x7 + x4\n",
      "AIC: 272.522, formula: y ~ x3 + x5 + x7 + x2\n",
      "AIC: 272.446, formula: y ~ x3 + x5 + x7 + x8\n",
      "The best formula: y ~ x3 + x5 + x7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#IV selection. \n",
    "cs=['y']\n",
    "cs2=['x{}'.format(i+1) for i in range(10)] # x1...xnの列名を生成する\n",
    "cs = cs + cs2\n",
    "#print(cs)\n",
    "d2=d\n",
    "d2.columns=cs\n",
    "d_scaled= preprocessing.scale(d2)\n",
    "d_scaled = pd.DataFrame(d_scaled)\n",
    "d_scaled.columns=cs\n",
    "d_scaled.head()\n",
    "model = step_aic(smf.ols, cs2,'y', data=d_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.249\n",
      "Model:                            OLS   Adj. R-squared:                  0.226\n",
      "Method:                 Least Squares   F-statistic:                     10.93\n",
      "Date:                Tue, 08 Jan 2019   Prob (F-statistic):           2.91e-06\n",
      "Time:                        11:52:49   Log-Likelihood:                -131.42\n",
      "No. Observations:                 103   AIC:                             270.8\n",
      "Df Residuals:                      99   BIC:                             281.4\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -5.204e-18      0.087  -5.97e-17      1.000      -0.173       0.173\n",
      "x1             0.2341      0.092      2.555      0.012       0.052       0.416\n",
      "x2            -0.2876      0.088     -3.266      0.001      -0.462      -0.113\n",
      "x3            -0.2314      0.091     -2.547      0.012      -0.412      -0.051\n",
      "==============================================================================\n",
      "Omnibus:                       11.716   Durbin-Watson:                   0.332\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):                4.830\n",
      "Skew:                          -0.262   Prob(JB):                       0.0894\n",
      "Kurtosis:                       2.077   Cond. No.                         1.38\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\honda\\Miniconda3\\envs\\stats\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Regression after IV selection.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "\n",
    "y2=d['y']\n",
    "X2=d[['x3', 'x5', 'x7']]\n",
    "\n",
    "y_scaled_2 = preprocessing.scale(y2)\n",
    "X_scaled_2 = preprocessing.scale(X2)\n",
    "\n",
    "#Regression for the comprehensive test.\n",
    "import statsmodels.api as sm\n",
    "mod2 = sm.OLS(y_scaled_2, sm.add_constant(X_scaled_2))\n",
    "res2 = mod2.fit()\n",
    "print(res2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.249\n",
      "Model:                            OLS   Adj. R-squared:                  0.226\n",
      "Method:                 Least Squares   F-statistic:                     10.93\n",
      "Date:                Tue, 08 Jan 2019   Prob (F-statistic):           2.91e-06\n",
      "Time:                        11:53:44   Log-Likelihood:                -480.82\n",
      "No. Observations:                 103   AIC:                             969.6\n",
      "Df Residuals:                      99   BIC:                             980.2\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        146.6544     34.387      4.265      0.000      78.423     214.886\n",
      "x3             0.0819      0.032      2.555      0.012       0.018       0.145\n",
      "x5            -3.0602      0.937     -3.266      0.001      -4.919      -1.201\n",
      "x7            -0.1091      0.043     -2.547      0.012      -0.194      -0.024\n",
      "==============================================================================\n",
      "Omnibus:                       11.716   Durbin-Watson:                   0.332\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):                4.830\n",
      "Skew:                          -0.262   Prob(JB):                       0.0894\n",
      "Kurtosis:                       2.077   Cond. No.                     1.00e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large,  1e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#Regression for the comprehensive test.\n",
    "import statsmodels.api as sm\n",
    "mod2 = sm.OLS(y2, sm.add_constant(X2))\n",
    "res2 = mod2.fit()\n",
    "print(res2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>176.280166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>1.106434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>1.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>1.087342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              VIF\n",
       "const  176.280166\n",
       "x3       1.106434\n",
       "x5       1.021383\n",
       "x7       1.087342"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VIF checkup.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "num_cols = mod2.exog.shape[1] \n",
    "vifs = [variance_inflation_factor(mod2.exog, i)\n",
    "        for i in range(0, num_cols)]\n",
    "pd.DataFrame(vifs, index=mod2.exog_names, columns=[\"VIF\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
