{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([6.2, 4.8, 5.3, 5.5, 5.1, 4.9, 4.7, 7.9, 6.6, 7.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1_mean = 5.0\n",
    "sample1_std = 120\n",
    "\n",
    "sample2_mean = 4450\n",
    "sampe2_std = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![検定早見表](images/スクリーンショット.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![メソッド一覧](images/how_to_use_method_ss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下は母平均に関する検定である。(z, t検定)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z検定\n",
    "母標準偏差既知の場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95%信頼区間推定\n",
    "alpha=信頼区間, loc=期待値（平均）, \n",
    "scale=統計量(標準偏差/√自由度（標本サイズ）)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.83"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.norm.interval(alpha=0.95, loc=5, scale=1/np.sqrt(len(data)))\n",
    "#ss.norm.interval(alpha=0.95, loc=np.mean(data), scale=np.std(data)/np.sqrt(len(data)))\n",
    "np.mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cdf(x=確率変数, loc=期待値, scale=標準偏差)\n",
    "累積分布関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63609918, 0.16629764, 0.30904469, 0.37811922, 0.24613721,\n",
       "       0.19083274, 0.14389833, 0.97424498, 0.76556628, 0.91663667])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.norm.cdf(ss.zscore(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ppf(q=パーセント点, loc=期待値, scale=標準偏差)\n",
    "パーセント点関数から正規分布の信頼区間の棄却点を導き出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z critical value: [-1.960, 1.960]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "z_critical_value = ss.norm.ppf(alpha/2)\n",
    "print(\"z critical value: [{:.3f}, {:.3f}]\".format(z_critical_value, -z_critical_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z値の算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criticulate z value: 2.946\n"
     ]
    }
   ],
   "source": [
    "z = (sample1_mean - sample2_mean) / (sample1_std / np.sqrt(50))\n",
    "print(\"Criticulate z value: {:.3f}\".format(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p値の算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d7f2a9515656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_critical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"P value: {:}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp_critical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "p_critical = ss.norm.cdf(z)\n",
    "print(\"P value: {:}\".format(1-p_critical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F分布 等分散性検定\n",
    "2つの母集団の分散の比の検定によく使われる。  \n",
    "自由度(n1, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value: 0.901\n"
     ]
    }
   ],
   "source": [
    "X = [0.3, 9.5, 13.6, 12.5, 11.6, 9.87, 9.4, 12.6, 11.6, 10.5]\n",
    "Y = [16.2, 11.6, 12.4, 14.1, 10.8, 13.8, 14.6, 15.4, 19.1, 13.9]\n",
    "F = np.var(X) / np.var(Y)\n",
    "df1 = len(X) - 1\n",
    "df2 = len(Y) - 1\n",
    "alpha = 0.05\n",
    "p_value = ss.f.cdf(F, df1, df2)\n",
    "print(\"p value: {:.3f}\".format(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_onewayResult(statistic=5.400987834994967, pvalue=0.028767554259032706)\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([9.5,9.7,10.1,9.8,9.3])\n",
    "a2 = np.array([10.1,10.5,9.6,9.3])\n",
    "a3 = np.array([11.3,10.7,10.2])\n",
    "\n",
    "res = ss.f_oneway(a1,a2,a3)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 水準間変動、残差変動、全変動\n",
    "![変動](images/図6.png)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "水準間変動: 62.07\n",
      " 残差変動: 83.40\n",
      " 全変動: 145.47\n"
     ]
    }
   ],
   "source": [
    "allline = np.asarray([a1,a2,a3]).reshape(-1)\n",
    "all_mean = np.mean(allline)\n",
    "a1_mean = np.mean(a1)\n",
    "a2_mean = np.mean(a2)\n",
    "a3_mean = np.mean(a3)\n",
    "\n",
    "total_var = np.sum([(i - all_mean)**2 for i in allline])\n",
    "level_var = np.sum((a1_mean - all_mean)**2 * len(a1) + (a2_mean - all_mean)**2 * len(a2) + (a3_mean - all_mean)**2 * len(a3))\n",
    "residual_var = total_var - level_var\n",
    "\n",
    "print(\"水準間変動: {:.2f}\\n 残差変動: {:.2f}\\n 全変動: {:.2f}\".format(level_var, residual_var, total_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t検定(t分布)\n",
    "母標準偏差が未知の場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パーセント点算出  \n",
    "ppf 累積分布関数の逆関数  \n",
    "ppf(0.975, 5)  \n",
    "ppf(パーセント点, 自由度(n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss.t.ppf(0.975, 5)\n",
    "#(155.25-147.4)/\n",
    "X = [160,168,158,165,161]\n",
    "Y = [153,155,149,152]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 つの母集団の<b>分散</b>が<b>同じとき</b>の t 検定  \n",
    "t_ss, prob = ss.ttest_ind(\n",
    "[データ1], [データ2], equal_var=True)  \n",
    "片側検定の場合、p値を1/2する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t value by scipy: 4.6219998185251905\n",
      "p value by scipy: 0.0027120104740654682\n"
     ]
    }
   ],
   "source": [
    "t_ss, prob = ss.ttest_ind(X,Y, equal_var=False)\n",
    "print(\"t value by scipy: {}\".format(t_ss))\n",
    "print(\"p value by scipy: {}\".format(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 つの母集団の<b>分散</b>が<b>同じでないとき</b>の t 検定\n",
    "t_ss, prob = ss.ttest_ind([データ１], [データ２], equal_var=True)  \n",
    "片側検定の場合、p値を1/2する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t value by scipy: 5.080348617271814\n",
      "p value by scipy: 0.00019131443517208103\n"
     ]
    }
   ],
   "source": [
    "t_ss, prob = ss.ttest_ind([1326,1418,1820,1516,1635,1720,1580,1452,1600], [1220,1080,980,1420,1170,1290,1116], equal_var=False)\n",
    "print(\"t value by scipy: {}\".format(t_ss))\n",
    "print(\"p value by scipy: {}\".format(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 従属な 2 群間 t 検定  \n",
    "> 例:ラットに薬剤を投与し、投与前と投与後の体重を測定したデータでは、それぞれのラットに対して投与前と投与後のデータがあるので、投与前と投与後のデータが対応しているといえる。  \n",
    "\n",
    "つまり、同じ長さの配列が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unequal length arrays",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-823dca83a697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_ss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttest_rel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1326\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1418\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1820\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1516\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1635\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1720\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1580\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1452\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1220\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m980\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1420\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1170\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1290\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1116\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t value by scipy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_ss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p value by scipy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-4.3.1/lib/python3.6/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mttest_rel\u001b[0;34m(a, b, axis, nan_policy)\u001b[0m\n\u001b[1;32m   4171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4173\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unequal length arrays'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unequal length arrays"
     ]
    }
   ],
   "source": [
    "t_ss, prob = ss.ttest_rel([1326,1418,1820,1516,1635,1720,1580,1452,1600], [1220,1080,980,1420,1170,1290,1116])\n",
    "print(\"t value by scipy: {}\".format(t_ss))\n",
    "print(\"p value by scipy: {}\".format(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二項検定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二項検定\n",
    "p = ss.binom_test(当たり回数, 試行回数, 確率)\n",
    "p = ss.binom_test(16, 20, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011817932128906248"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.binom_test(16, 20, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X^2検定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パーセント点算出\n",
    "ss.chi2.ppf(パーセント点, 自由度(n-1))\n",
    "![カイニ乗検定1](images/図3.png)\n",
    "![カイニ乗検定2](images/図4.png)\n",
    "ss.chi2.ppf(0.95, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.chi2.ppf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二次元以上のchi2検定\n",
    "> 次の表は、ある小学校の1年生と年生に好きなスポーツを質問した結果である。この結果から、1年生と2年生のスポーツの好みに関連があるかどうかを有意水準0.05で検定せよ。\n",
    "![カイニ乗検定3](images/図5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test statistic:  4.044612794612794\n",
      "p-value: 0.044312543173412496\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[9,3],[18,30]])\n",
    "result = ss.chi2_contingency(array)\n",
    "print(\"test statistic: \", result[0])\n",
    "print(\"p-value:\", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x^2検定\n",
    "理論値  \n",
    "ss.stats.chisquare([適合度検定データ],f_exp=[理論値])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=20.6, pvalue=0.014549902304087554)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stats.chisquare([32,16,18,19,17,25,11,16,30,16],f_exp=[20,20,20,20,20,20,20,20,20,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxonの順位和検定  \n",
    "- 2グループの標本について、それぞれの母集団の中央値に差があるかどうかの検定\n",
    "- 今までの様に分布を特定のものに限定しない  \n",
    "- ２つの分布の形は同じそうだが、位置がずれているか？の判断に特に有効  \n",
    "- 標本の値そのものではなく、順位に置き換えて検定統計量を求めるのが特徴  \n",
    "ss.mannwhitneyu([data1],[data2], alternative=\"two-sided\")  \n",
    "<-alternativeパラメータ(\"two-sided\",\"less\",\"greater\")\n",
    "> 東京と大阪の住人を無作為に8人ずつ選んで、内閣支持に関するアンケートを行った。\n",
    "5: 支持する、4:やや支持する、3:どちらとも言えない、2:やや支持しない、1:支持しない\n",
    "以下の結果から、東京と大阪で内閣に対する意見は異なっているか検定せよ。  \n",
    "\n",
    "|東京|大阪|\n",
    "|:--:|:--:|\n",
    "|4|3|\n",
    "|3|3|\n",
    "|3|1|\n",
    "|2|5|\n",
    "|1|2|\n",
    "|3|5|\n",
    "|4|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=21.0, pvalue=0.03082895140322003)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.mannwhitneyu([7.5,6.3,6.0,8.0,9.2,6.0,7.5,4.5,5.5,6.0],[8.3,5.8,6.1,8.1,8.9,10.4,13.0,6.1,10.1\n",
    ",9.4], alternative=\"two-sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxonの符号順位検定\n",
    "- 対応が有る2グループの標本についての標本について、それぉれの母集団の中央値に差があるかどうかの検定\n",
    "- 今までのように分布を特定のものに限定しない\n",
    "- 2ツノ分布の形は同じそうだが、位置がずれているかの判断に特に有効\n",
    "> n人の対象者に省エネ活動の指導を行いその前後での意識調査の結果を比較する\n",
    "> ある新薬の効果を試すために被験者8名を集めた。\u000b",
    "まず8名のγ-GTP値を計測し、その後2ヶ月新薬を服用してもらい、2ヶ月後γ-GTP値を再計測した。\u000b",
    "結果は以下のとおりである。Wilcoxonの符号順位検定により、新薬に効果があるかどうかを有意水準5%で検定せよ。\n",
    "\n",
    "|被験者番号|投薬前|投薬後|\n",
    "|:--:|:--:|:--:|\n",
    "|1|100|95|\n",
    "|2|110|100|\n",
    "|3|120|105|\n",
    "|4|130|110|\n",
    "|5|135|120|\n",
    "|6|140|145|\n",
    "|7|220|170|\n",
    "|8|250|195|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "wilcoxon() got an unexpected keyword argument 'alternative'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2d95cd962151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ss.wilcoxon([7.5,6.3,6.0,8.0,9.2,6.0,7.5,4.5,5.5,6.0],[8.3,5.8,6.1,8.1,8.9,10.4,13.0,6.1,10.1\n\u001b[0;32m----> 2\u001b[0;31m ,9.4], alternative=\"one-sided\")\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: wilcoxon() got an unexpected keyword argument 'alternative'"
     ]
    }
   ],
   "source": [
    "ss.wilcoxon([7.5,6.3,6.0,8.0,9.2,6.0,7.5,4.5,5.5,6.0],[8.3,5.8,6.1,8.1,8.9,10.4,13.0,6.1,10.1\n",
    ",9.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisherの正確確率検定\n",
    "- 2つのカテゴリーに分類されたデータの分析(標本数が小さい場合)\n",
    "- 2 x 2分割表(2つの集団が2カテゴリーに分類されたデータを扱う場合、自由度は1)の2変数の間に統計学的に有意な関連があるかどうかを調べる\n",
    "- 同じ状況で<b>標本の大きさが大きい場合</b>には統計量の標本分布が近似的にカイ二乗分布に等しくなるので<b>カイ二乗検定</b>が用いられる\n",
    "- 標本の大きさが小さい（分割表のセルの期待値に10未満のものがある）場合や、表中の数値の偏りが大きい場合にはこの近似は不正確。この場合には正確確率検定が正確\n",
    "- 逆にサンプルサイズが大きい場合や、数値の偏りが小さい場合にはカイニ検定が良い。\n",
    "> 男女各5人にある政策の賛否をアンケートしたところ，以下の結果を得た．男女間で賛否に有意な差があると言えるか。\n",
    "\n",
    "![男女表](images/図1.png)  \n",
    "\n",
    "> 以下の様な表で、「甘いものがすきか嫌いか」と「虫歯の有無」の間に関連があるかどうかを検定せよ。\n",
    "有意水準5%の両側検定を実施せよ。\n",
    "![虫歯と甘いもの](images/図2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odds ratio:8.0\n",
      "p値:0.0697785186949274\n"
     ]
    }
   ],
   "source": [
    "dat_edit = np.array([[6,2],[3,8]])\n",
    "odds, p = ss.fisher_exact(dat_edit)\n",
    "\n",
    "print(\"odds ratio:\" + str(odds))\n",
    "print(\"p値:\"+ str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分散分析 二元配置分散分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ルビーン検定\n",
    "集団が正規分布から乖離している場合に使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.levene()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バートレット検定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.bartlett()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 対比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turkey法（サンプルサイズ同じ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データは多次元配置のnparray\n",
    "A = np.array([])\n",
    "B = np.array([])\n",
    "C = np.array([])\n",
    "D = np.array([])\n",
    "\n",
    "data_arr = np.hstack((A,B,C,D))\n",
    "ind_arr = np.reoeat(list(\"ABCD\"), len(A))\n",
    "print(pairwise_tukeyhsd(data_arr, ind_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turkey-Kramer法（サンプルサイズ違ってもいい）\n",
    "正規性が前提"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD,FWER=0.05\n",
      "===========================================\n",
      "group1 group2 meandiff  lower  upper reject\n",
      "-------------------------------------------\n",
      "  A      B     0.195    -0.647 1.037 False \n",
      "  A      C     1.0533   0.1366  1.97  True \n",
      "  B      C     0.8583  -0.1004 1.817 False \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''A = [14, 15, 14, 16, 15, 17, 17]\n",
    "B = [17, 16, 17, 16, 15, 18, 19, 15]\n",
    "C = [18, 19, 20, 19, 17, 17]\n",
    "D = [20, 21, 19, 20, 19, 22, 20]\n",
    "E = [19, 20, 19, 17, 17, 17, 18]\n",
    "'''\n",
    "\n",
    "A = np.array([9.5,9.7,10.1,9.8,9.3])\n",
    "B = np.array([10.1,10.5,9.6,9.3])\n",
    "C = np.array([11.3,10.7,10.2])\n",
    "\n",
    "\n",
    "def tukey_hsd( ind, *args ):\n",
    "    data_arr = np.hstack( args )\n",
    "    ind_arr = np.array([])\n",
    "    for x in range(len(args)):\n",
    "      ind_arr = np.append(ind_arr, np.repeat(ind[x], len(args[x])))\n",
    "    print(pairwise_tukeyhsd(data_arr,ind_arr))\n",
    "\n",
    "#tukey_hsd(list('ABC') , A,B,C) # 第1引数:名称のリスト, 第2引数以降: データ\n",
    "if __name__ == \"__main__\":\n",
    "    tukey_hsd(list(\"ABC\"), A, B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steel-Dwass test検定\n",
    "正規性なしでも可  \n",
    "ただし等分散性は必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1  2  3   4  5  6  7  8  9\n",
      "g1  5  4  6  3   3  7  6  5  3  5\n",
      "g2  8  4  3  3   7  9  8  7  3  4\n",
      "g3  7  6  8  9  10  9  8  9  7  8\n",
      "                 t         p\n",
      "(g1, g2)  0.808763  0.680859\n",
      "(g1, g3)  3.585362  0.001000\n",
      "(g2, g3)  2.268701  0.060304\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Here, we use pstrurng() in statsmodels that can be imported as below:\n",
    "\n",
    "        from statsmodels.stats.libqsturng import psturng\n",
    "\n",
    "pstrung(q, r, v) is used to evaluates the probability from 0 to q for a\n",
    "            studentized range having v degrees of freedom and r samples.\n",
    "\n",
    "  Definition of the function:\n",
    "\n",
    "    def psturng(q, r, v):\n",
    "        Parameters\n",
    "        ----------\n",
    "        q : (scalar, array_like)\n",
    "            quantile value of Studentized Range\n",
    "            q >= 0.\n",
    "        r : (scalar, array_like)\n",
    "            The number of samples\n",
    "            r >= 2 and r <= 200\n",
    "            (values over 200 are permitted but not recommended)\n",
    "        v : (scalar, array_like)\n",
    "            The sample degrees of freedom\n",
    "            if p >= .9:\n",
    "                v >=1 and v >= inf\n",
    "            else:\n",
    "                v >=2 and v >= inf\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        p : (scalar, array_like)\n",
    "            1. - area from zero to q under the Studentized Range\n",
    "            distribution. When v == 1, p is bound between .001\n",
    "            and .1, when v > 1, p is bound between .001 and .9.\n",
    "            Values between .5 and .9 are 1st order appoximations.\n",
    "\n",
    "Because it uses interpolation from R data, the probability of CDF is not\n",
    "exactly same as the one from R's ptukey().\n",
    "E.g.,\n",
    "   Python:\n",
    "    >>print(psturng(3.997799075635331, 10, 465.4956))\n",
    "    0.13000739280348494\n",
    "\n",
    "   R:\n",
    "    > 1 - ptukey(3.997799075635331,  10, 465.4956)\n",
    "    0.1305053\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "def flatten(*iterables):\n",
    "    \"\"\" Recursive flatten a nested list \"\"\"\n",
    "    for s in iterables:\n",
    "        try:\n",
    "            it_is = iter(s)\n",
    "        except TypeError:\n",
    "            yield s\n",
    "        else:\n",
    "            for i in it_is:\n",
    "                for j in flatten(i):\n",
    "                    yield j\n",
    "\n",
    "def steel_dwass(data, rank_method='average'):\n",
    "    \"\"\"\n",
    "    Steel-Dwass pairwise ranking test\n",
    "\n",
    "    This function rewritten in Python refers to\n",
    "\n",
    "    The Steel Dwass method performs the multiple comparisons whilst\n",
    "    controlling the overall experiment-wise error rate\n",
    "    (it is the non-parametric equivalent to the Tukey All-Pairs method)\n",
    "     adapted from http://aoki2.si.gunma-u.ac.jp/R/Steel-Dwass.html\n",
    "\n",
    "\n",
    "    Args:\n",
    "        data(pandas dataframe):\n",
    "            data with more than 3 groups\n",
    "    Kwargs:\n",
    "        rank_method (str, optional):\n",
    "            The method used to assign ranks to tied elements.\n",
    "            The options are ‘average’, ‘min’, ‘max’, ‘dense’ and ‘ordinal’.\n",
    "\n",
    "        alpha (float): the significant level. Default is 0.05\n",
    "    Returns:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    import itertools as it\n",
    "    from statsmodels.stats.libqsturng import psturng\n",
    "\n",
    "    r_method_types = ['average', 'min', 'max', 'dense', 'ordinal']\n",
    "    if rank_method not in r_method_types:\n",
    "        raise ValueError(\"Unknown rank method: \"\n",
    "                         \"it should be 'average', \"\n",
    "                         \"'min', 'max', 'dense', 'ordinal'\")\n",
    "\n",
    "    # The rows are used as samples.\n",
    "    cols = data.index\n",
    "    ngroups = len(cols)\n",
    "    if ngroups < 3:\n",
    "        raise ValueError(\"The input data should more than 3 groups\")\n",
    "\n",
    "    # Make combinations\n",
    "    combs = list(it.combinations(cols, 2))\n",
    "    static = []\n",
    "\n",
    "    for d in combs:\n",
    "        # flatten to a list\n",
    "        d1 = list(flatten(data.loc[d[0]].values))\n",
    "        d2 = list(flatten(data.loc[d[1]].values))\n",
    "        # length for each rpws\n",
    "        d1_num = len(d1)\n",
    "        d2_num = len(d2)\n",
    "        # Total number of elements\n",
    "        N = d1_num + d2_num\n",
    "        # concatenate two lists\n",
    "        d1_d2 = d1 + d2\n",
    "        # get the rank for the combined list\n",
    "        r = ss.rankdata(d1_d2, method=rank_method)\n",
    "        \n",
    "        R = sum(r[:d1_num])\n",
    "        E = d1_num * (N + 1) / 2\n",
    "        V = d1_num * d2_num/(N * (N - 1)) * (sum(r**2) - N * (N + 1)**2/4)\n",
    "        t = abs(R - E) / np.sqrt(V)\n",
    "        # Tukey cdf\n",
    "        p_val = psturng(t * np.sqrt(2), ngroups, np.inf)\n",
    "        static.append([t, p_val])\n",
    "\n",
    "    return pd.DataFrame(static, columns=['t', 'p'], index=combs)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # The sample data as shown in R\n",
    "    \n",
    "    data = [[5,4,6,3,3,7,6,5,3,5],\n",
    "            [8,4,3,3,7,9,8,7,3,4],\n",
    "            [7,6,8,9,10,9,8,9,7,8]]\n",
    "        \n",
    "#    data = [[6.9, 7.5, 8.5, 8.4, 8.1, 8.7, 8.9, 8.2, 7.8, 7.3, 6.8],\n",
    "#            [9.6, 9.4, 9.5, 8.5, 9.4, 9.9, 8.7, 8.1, 7.8, 8.8],\n",
    "#            [5.7, 6.4, 6.8, 7.8, 7.6, 7.0, 7.7, 7.5, 6.8, 5.9],\n",
    "#            [7.6, 8.7, 8.5, 8.5, 9.0, 9.2, 9.3, 8.0, 7.2, 7.9, 7.8]]\n",
    "    # add row indices\n",
    "    inx = ['g1', 'g2', 'g3']\n",
    "    data = np.asarray(data)\n",
    "    # Convert to dataframe\n",
    "    #\n",
    "    df = pd.DataFrame(data, index=inx)\n",
    "    # call the self-defined function\n",
    "    mc = steel_dwass(df)\n",
    "    print(df)\n",
    "    print(mc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kruskal-Wallis one-way analysis of variance\n",
    "![Kruskal](images/kkk.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ss.kruskal([],[],[])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0 = 1008\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
